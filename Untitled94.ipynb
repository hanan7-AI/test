{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa128c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tflite_runtime.interpreter as tflite  # Use tflite_runtime for lightweight TensorFlow Lite inference\n",
    "\n",
    "def run_tflite_inference(model_path, feature_vector):\n",
    "    # Initialize TFLite interpreter\n",
    "    interpreter = tflite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Adjust feature vector shape to match the model's input shape\n",
    "    input_shape = input_details[0]['shape']\n",
    "    if feature_vector.shape != tuple(input_shape):\n",
    "        # Reshape or add batch dimension if necessary\n",
    "        feature_vector = np.expand_dims(feature_vector, axis=0)\n",
    "\n",
    "    # Set tensor to input data\n",
    "    interpreter.set_tensor(input_details[0]['index'], feature_vector.astype(np.float32))\n",
    "\n",
    "    # Invoke model\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get output data\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return output_data\n",
    "\n",
    "# Paths\n",
    "model_path = \"path/to/your/model.tflite\"  # Replace with your model path\n",
    "audio_file_path = \"path/to/your/audio.wav\"  # Replace with your audio file path\n",
    "\n",
    "# Extract features from the audio file\n",
    "param = yaml_load()  # Load parameters from baseline.yaml\n",
    "feature_vector = file_to_vector_array(\n",
    "    file_name=audio_file_path,\n",
    "    n_mels=param['feature']['n_mels'],\n",
    "    frames=param['feature']['frames'],\n",
    "    n_fft=param['feature']['n_fft'],\n",
    "    hop_length=param['feature']['hop_length'],\n",
    "    power=param['feature']['power']\n",
    ")\n",
    "\n",
    "# Run inference\n",
    "output = run_tflite_inference(model_path, feature_vector)\n",
    "print(\"Inference Output:\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
